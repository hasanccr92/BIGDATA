{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This is the labelling and preparation of our own data which we collected from Twitter (X)"
      ],
      "metadata": {
        "id": "vTV2ZJoVH2o5"
      },
      "id": "vTV2ZJoVH2o5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba6dfc63",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-25T16:09:07.565620Z",
          "iopub.status.busy": "2025-04-25T16:09:07.565300Z",
          "iopub.status.idle": "2025-04-25T16:09:11.909141Z",
          "shell.execute_reply": "2025-04-25T16:09:11.908062Z"
        },
        "papermill": {
          "duration": 4.351482,
          "end_time": "2025-04-25T16:09:11.911502",
          "exception": false,
          "start_time": "2025-04-25T16:09:07.560020",
          "status": "completed"
        },
        "tags": [],
        "id": "ba6dfc63",
        "outputId": "ab4b606c-ad75-49ff-d704-81b082a44eb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/vevfvs/Raw X Data/inference_tweets2_10_04.csv\n",
            "/kaggle/input/vevfvs/Raw X Data/amazing_tweets_05_04.csv\n",
            "/kaggle/input/vevfvs/Raw X Data/inference_tweets1_10_04.csv\n",
            "/kaggle/input/vevfvs/Raw X Data/horrified11_04.csv\n",
            "/kaggle/input/vevfvs/Raw X Data/inference_tweets_05_04.csv\n",
            "/kaggle/input/vevfvs/Raw X Data/worse_tweets_05_04.csv\n",
            "/kaggle/input/vevfvs/Raw X Data/furious_tweets_11_04.csv\n",
            "/kaggle/input/vevfvs/Raw X Data/inference_tweets_05_04_1.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import re\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import random\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc0b837",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:09:11.920752Z",
          "iopub.status.busy": "2025-04-25T16:09:11.920301Z",
          "iopub.status.idle": "2025-04-25T16:09:11.989891Z",
          "shell.execute_reply": "2025-04-25T16:09:11.988665Z"
        },
        "papermill": {
          "duration": 0.076575,
          "end_time": "2025-04-25T16:09:11.992266",
          "exception": false,
          "start_time": "2025-04-25T16:09:11.915691",
          "status": "completed"
        },
        "tags": [],
        "id": "7dc0b837"
      },
      "outputs": [],
      "source": [
        "#Combine all files to one\n",
        "\n",
        "import glob\n",
        "\n",
        "# List of file paths\n",
        "file_paths = [\n",
        "    '/kaggle/input/vevfvs/Raw X Data/inference_tweets2_10_04.csv',\n",
        "    '/kaggle/input/vevfvs/Raw X Data/amazing_tweets_05_04.csv',\n",
        "    '/kaggle/input/vevfvs/Raw X Data/inference_tweets1_10_04.csv',\n",
        "    '/kaggle/input/vevfvs/Raw X Data/horrified11_04.csv',\n",
        "    '/kaggle/input/vevfvs/Raw X Data/inference_tweets_05_04.csv',\n",
        "    '/kaggle/input/vevfvs/Raw X Data/worse_tweets_05_04.csv',\n",
        "    '/kaggle/input/vevfvs/Raw X Data/furious_tweets_11_04.csv',\n",
        "    '/kaggle/input/vevfvs/Raw X Data/inference_tweets_05_04_1.csv'\n",
        "]\n",
        "\n",
        "# Read and concatenate all CSVs\n",
        "df_combined = pd.concat([pd.read_csv(fp) for fp in file_paths], ignore_index=True)\n",
        "\n",
        "# Save to CSV\n",
        "df_combined.to_csv('combined_tweets.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "533fff0f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:09:12.001598Z",
          "iopub.status.busy": "2025-04-25T16:09:12.001280Z",
          "iopub.status.idle": "2025-04-25T16:09:12.029772Z",
          "shell.execute_reply": "2025-04-25T16:09:12.029051Z"
        },
        "papermill": {
          "duration": 0.034751,
          "end_time": "2025-04-25T16:09:12.031476",
          "exception": false,
          "start_time": "2025-04-25T16:09:11.996725",
          "status": "completed"
        },
        "tags": [],
        "id": "533fff0f",
        "outputId": "7fd48cce-041b-49be-cb6f-8095a8408d23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>keyword</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is a project that I am exceedingly happy ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:53+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@RadioEuropes @Keir_Starmer @MayorofLondon Is ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:53+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>â˜˜  I was just in it up in this booth off the t...</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:53+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Happy to be of serviceðŸ«¡ https://t.co/bZy1IJ1BO...</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:52+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Eminascrypt Happy Thursday Eminas</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:51+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@PamelaDost27628 Happy birthday!! https://t.co...</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:51+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@Dreymwangi Haters hampendi kuniona happyðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:50+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Idk wtf going on on New York Ave but Iâ€™m so ha...</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:50+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@binibloombelge @bini_sheena The strength and ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:50+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I GOT THE PERSON I WANT, I'M HAPPY NOW BYEEEE</td>\n",
              "      <td>happy</td>\n",
              "      <td>2025-04-10 19:57:50+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text keyword  \\\n",
              "0  This is a project that I am exceedingly happy ...   happy   \n",
              "1  @RadioEuropes @Keir_Starmer @MayorofLondon Is ...   happy   \n",
              "2  â˜˜  I was just in it up in this booth off the t...   happy   \n",
              "3  Happy to be of serviceðŸ«¡ https://t.co/bZy1IJ1BO...   happy   \n",
              "4                 @Eminascrypt Happy Thursday Eminas   happy   \n",
              "5  @PamelaDost27628 Happy birthday!! https://t.co...   happy   \n",
              "6     @Dreymwangi Haters hampendi kuniona happyðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚   happy   \n",
              "7  Idk wtf going on on New York Ave but Iâ€™m so ha...   happy   \n",
              "8  @binibloombelge @bini_sheena The strength and ...   happy   \n",
              "9      I GOT THE PERSON I WANT, I'M HAPPY NOW BYEEEE   happy   \n",
              "\n",
              "                  created_at  \n",
              "0  2025-04-10 19:57:53+00:00  \n",
              "1  2025-04-10 19:57:53+00:00  \n",
              "2  2025-04-10 19:57:53+00:00  \n",
              "3  2025-04-10 19:57:52+00:00  \n",
              "4  2025-04-10 19:57:51+00:00  \n",
              "5  2025-04-10 19:57:51+00:00  \n",
              "6  2025-04-10 19:57:50+00:00  \n",
              "7  2025-04-10 19:57:50+00:00  \n",
              "8  2025-04-10 19:57:50+00:00  \n",
              "9  2025-04-10 19:57:50+00:00  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_combined.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b131f50",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:09:12.040495Z",
          "iopub.status.busy": "2025-04-25T16:09:12.040215Z",
          "iopub.status.idle": "2025-04-25T16:09:12.054202Z",
          "shell.execute_reply": "2025-04-25T16:09:12.053146Z"
        },
        "papermill": {
          "duration": 0.020959,
          "end_time": "2025-04-25T16:09:12.056215",
          "exception": false,
          "start_time": "2025-04-25T16:09:12.035256",
          "status": "completed"
        },
        "tags": [],
        "id": "7b131f50"
      },
      "outputs": [],
      "source": [
        "df_combined = df_combined.drop(['keyword'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adfcf923",
      "metadata": {
        "papermill": {
          "duration": 0.00325,
          "end_time": "2025-04-25T16:09:12.063420",
          "exception": false,
          "start_time": "2025-04-25T16:09:12.060170",
          "status": "completed"
        },
        "tags": [],
        "id": "adfcf923"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fef1652",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:09:12.073831Z",
          "iopub.status.busy": "2025-04-25T16:09:12.073326Z",
          "iopub.status.idle": "2025-04-25T16:09:12.084443Z",
          "shell.execute_reply": "2025-04-25T16:09:12.083259Z"
        },
        "papermill": {
          "duration": 0.018595,
          "end_time": "2025-04-25T16:09:12.087044",
          "exception": false,
          "start_time": "2025-04-25T16:09:12.068449",
          "status": "completed"
        },
        "tags": [],
        "id": "1fef1652"
      },
      "outputs": [],
      "source": [
        "df_combined.to_csv('curated_dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used a microsoft AI's fine tuned version of DeepSeek"
      ],
      "metadata": {
        "id": "UnNlSn0XHvl-"
      },
      "id": "UnNlSn0XHvl-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a583839",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:09:12.098835Z",
          "iopub.status.busy": "2025-04-25T16:09:12.097320Z",
          "iopub.status.idle": "2025-04-25T16:09:12.120144Z",
          "shell.execute_reply": "2025-04-25T16:09:12.118875Z"
        },
        "papermill": {
          "duration": 0.031141,
          "end_time": "2025-04-25T16:09:12.122460",
          "exception": false,
          "start_time": "2025-04-25T16:09:12.091319",
          "status": "completed"
        },
        "tags": [],
        "id": "3a583839"
      },
      "outputs": [],
      "source": [
        "def detect_emotion(sentence: str, max_retries=5) -> str:\n",
        "    # Initialize the client (replace with your API key)\n",
        "    client = OpenAI(\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        api_key = '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'\n",
        "    )\n",
        "\n",
        "    # Enhanced prompt with stronger directives for a single-word response\n",
        "    prompt = f\"\"\"Analyze the following text and detect the emotional tone, then assign EXACTLY ONE emotion from this list: [anger, fear, joy, love, sadness].\n",
        "\n",
        "IMPORTANT: Your response must contain ONLY a single word - one of these five emotions. No explanations, punctuation, or additional text.\n",
        "\n",
        "Text to analyze: \"{sentence}\"\n",
        "\n",
        "Primary emotion (single word only):\"\"\"\n",
        "\n",
        "    valid_emotions = [\"anger\", \"fear\", \"joy\", \"love\", \"sadness\"]\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            # Make the API call\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"microsoft/mai-ds-r1:free\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=10,\n",
        "                temperature=0.1,  # Even lower temperature for consistency\n",
        "            )\n",
        "\n",
        "            # Extract and clean the response\n",
        "            if response.choices and response.choices[0].message.content:\n",
        "                text = response.choices[0].message.content.lower().strip()\n",
        "\n",
        "                # Direct string match first (most reliable)\n",
        "                if text in valid_emotions:\n",
        "                    return text\n",
        "\n",
        "                # If not direct match, try to find any valid emotion in the response\n",
        "                for emotion in valid_emotions:\n",
        "                    if emotion in text:\n",
        "                        return emotion\n",
        "\n",
        "            # Wait before retrying\n",
        "            time.sleep(1 + attempt)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"API error on attempt {attempt + 1}: {str(e)}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(2 ** attempt)  # Exponential backoff\n",
        "\n",
        "    # Improved fallback: Lexicon-based with better weighting\n",
        "    emotion_keywords = {\n",
        "        \"joy\": [\"happy\", \"great\", \"glad\", \"excited\", \"awesome\", \"yay\", \"wonderful\", \"pleased\",\n",
        "                \"delighted\", \"thrilled\", \"enjoy\", \"fun\", \"laugh\", \"smile\", \"bright\", \"good\", \"positive\"],\n",
        "        \"sadness\": [\"sad\", \"sorry\", \"miss\", \"hurt\", \"pain\", \"disappointed\", \"upset\", \"grief\",\n",
        "                   \"depressed\", \"unhappy\", \"crying\", \"tears\", \"regret\", \"lost\", \"alone\", \"bad\"],\n",
        "        \"anger\": [\"angry\", \"hate\", \"mad\", \"damn\", \"fury\", \"outraged\", \"annoyed\", \"irritated\",\n",
        "                 \"frustrated\", \"betrayed\", \"rage\", \"furious\", \"upset\", \"bitter\", \"resent\"],\n",
        "        \"fear\": [\"scared\", \"fear\", \"afraid\", \"terrified\", \"worried\", \"anxious\", \"nervous\",\n",
        "                \"dread\", \"panic\", \"horrified\", \"frightened\", \"concern\", \"stress\", \"terror\"],\n",
        "        \"love\": [\"love\", \"cute\", \"sweet\", \"adore\", \"affection\", \"darling\", \"cherish\", \"care\",\n",
        "               \"admire\", \"fond\", \"devoted\", \"appreciation\", \"passion\", \"warmth\", \"heart\"]\n",
        "    }\n",
        "\n",
        "    # Count matches for each emotion\n",
        "    sentence_lower = sentence.lower()\n",
        "    scores = {emotion: 0 for emotion in valid_emotions}\n",
        "\n",
        "    for emotion, keywords in emotion_keywords.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in sentence_lower:\n",
        "                scores[emotion] += 1\n",
        "\n",
        "    # Find emotion with highest score\n",
        "    max_score = max(scores.values())\n",
        "\n",
        "    # If we have matches, return the emotion with highest score\n",
        "    if max_score > 0:\n",
        "        # Get all emotions with the max score\n",
        "        max_emotions = [e for e, s in scores.items() if s == max_score]\n",
        "        return random.choice(max_emotions)  # Randomly choose if multiple have same score\n",
        "\n",
        "    # Basic sentiment analysis as another fallback\n",
        "    sentiment_words = {\n",
        "        \"positive\": [\"good\", \"nice\", \"great\", \"better\", \"best\", \"amazing\", \"excellent\", \"perfect\", \"beautiful\"],\n",
        "        \"negative\": [\"bad\", \"worse\", \"worst\", \"terrible\", \"awful\", \"horrible\", \"poor\", \"wrong\", \"broken\"]\n",
        "    }\n",
        "\n",
        "    positive_count = sum(1 for word in sentiment_words[\"positive\"] if word in sentence_lower)\n",
        "    negative_count = sum(1 for word in sentiment_words[\"negative\"] if word in sentence_lower)\n",
        "\n",
        "    # Map sentiment to emotions\n",
        "    if positive_count > negative_count:\n",
        "        return random.choice([\"joy\", \"love\"])\n",
        "    elif negative_count > positive_count:\n",
        "        return random.choice([\"sadness\", \"anger\", \"fear\"])\n",
        "\n",
        "    # Final fallback: balanced random selection\n",
        "    return random.choice(valid_emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d480bcc7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:09:12.131007Z",
          "iopub.status.busy": "2025-04-25T16:09:12.130686Z",
          "iopub.status.idle": "2025-04-25T16:12:04.232426Z",
          "shell.execute_reply": "2025-04-25T16:12:04.231344Z"
        },
        "papermill": {
          "duration": 172.108562,
          "end_time": "2025-04-25T16:12:04.234736",
          "exception": false,
          "start_time": "2025-04-25T16:09:12.126174",
          "status": "completed"
        },
        "tags": [],
        "id": "d480bcc7"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/kaggle/input/vevfvs/Raw X Data/inference_tweets_05_04.csv')\n",
        "df['emotion'] = df['text'].apply(detect_emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84525844",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:12:04.244436Z",
          "iopub.status.busy": "2025-04-25T16:12:04.244114Z",
          "iopub.status.idle": "2025-04-25T16:12:04.255555Z",
          "shell.execute_reply": "2025-04-25T16:12:04.254436Z"
        },
        "papermill": {
          "duration": 0.018996,
          "end_time": "2025-04-25T16:12:04.258034",
          "exception": false,
          "start_time": "2025-04-25T16:12:04.239038",
          "status": "completed"
        },
        "tags": [],
        "id": "84525844",
        "outputId": "1e156236-e4df-4c78-de67-86b4404c153f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>keyword</th>\n",
              "      <th>created_at</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@OdiCrypt Please follow this guy @pithik29\\n\\n...</td>\n",
              "      <td>awesome</td>\n",
              "      <td>2025-04-05 19:55:36+00:00</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Awesome sunset over the city tonight! The colo...</td>\n",
              "      <td>awesome</td>\n",
              "      <td>2025-04-05 19:55:36+00:00</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Want to learn the secret to awesome game desig...</td>\n",
              "      <td>awesome</td>\n",
              "      <td>2025-04-05 19:55:36+00:00</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@imnoteru @especular_recto @SafetyAlpaca @GilA...</td>\n",
              "      <td>awesome</td>\n",
              "      <td>2025-04-05 19:55:36+00:00</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@LevisNFT This guy is awesome\\n@okyzawahyu\\nNe...</td>\n",
              "      <td>awesome</td>\n",
              "      <td>2025-04-05 19:55:36+00:00</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  keyword  \\\n",
              "0  @OdiCrypt Please follow this guy @pithik29\\n\\n...  awesome   \n",
              "1  Awesome sunset over the city tonight! The colo...  awesome   \n",
              "2  Want to learn the secret to awesome game desig...  awesome   \n",
              "3  @imnoteru @especular_recto @SafetyAlpaca @GilA...  awesome   \n",
              "4  @LevisNFT This guy is awesome\\n@okyzawahyu\\nNe...  awesome   \n",
              "\n",
              "                  created_at emotion  \n",
              "0  2025-04-05 19:55:36+00:00     joy  \n",
              "1  2025-04-05 19:55:36+00:00     joy  \n",
              "2  2025-04-05 19:55:36+00:00     joy  \n",
              "3  2025-04-05 19:55:36+00:00     joy  \n",
              "4  2025-04-05 19:55:36+00:00   anger  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123f7d4a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T16:12:04.267341Z",
          "iopub.status.busy": "2025-04-25T16:12:04.267060Z",
          "iopub.status.idle": "2025-04-25T17:54:09.980042Z",
          "shell.execute_reply": "2025-04-25T17:54:09.979142Z"
        },
        "papermill": {
          "duration": 6125.719598,
          "end_time": "2025-04-25T17:54:09.981734",
          "exception": false,
          "start_time": "2025-04-25T16:12:04.262136",
          "status": "completed"
        },
        "tags": [],
        "id": "123f7d4a"
      },
      "outputs": [],
      "source": [
        "df_combined['emotion'] = df_combined['text'].apply(detect_emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ad45f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T17:54:09.991153Z",
          "iopub.status.busy": "2025-04-25T17:54:09.990834Z",
          "iopub.status.idle": "2025-04-25T17:54:10.004021Z",
          "shell.execute_reply": "2025-04-25T17:54:10.003066Z"
        },
        "papermill": {
          "duration": 0.019225,
          "end_time": "2025-04-25T17:54:10.005431",
          "exception": false,
          "start_time": "2025-04-25T17:54:09.986206",
          "status": "completed"
        },
        "tags": [],
        "id": "11ad45f4"
      },
      "outputs": [],
      "source": [
        "# Step 2: Clean the text - remove @usernames and extra whitespace\n",
        "def clean_text(text):\n",
        "    # Remove all @usernames\n",
        "    text = re.sub(r'@\\w+', '', str(text))\n",
        "    # Remove extra whitespace and line breaks\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df_combined['clean_text'] = df_combined['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a9b4fcf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-25T17:54:10.037079Z",
          "iopub.status.busy": "2025-04-25T17:54:10.036746Z",
          "iopub.status.idle": "2025-04-25T17:54:10.048107Z",
          "shell.execute_reply": "2025-04-25T17:54:10.046984Z"
        },
        "papermill": {
          "duration": 0.017824,
          "end_time": "2025-04-25T17:54:10.049700",
          "exception": false,
          "start_time": "2025-04-25T17:54:10.031876",
          "status": "completed"
        },
        "tags": [],
        "id": "0a9b4fcf"
      },
      "outputs": [],
      "source": [
        "df_combined.to_csv(\"labeled_emotions.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a498c04",
      "metadata": {
        "papermill": {
          "duration": 0.003387,
          "end_time": "2025-04-25T17:54:10.057738",
          "exception": false,
          "start_time": "2025-04-25T17:54:10.054351",
          "status": "completed"
        },
        "tags": [],
        "id": "3a498c04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f165487",
      "metadata": {
        "papermill": {
          "duration": 0.003405,
          "end_time": "2025-04-25T17:54:10.065115",
          "exception": false,
          "start_time": "2025-04-25T17:54:10.061710",
          "status": "completed"
        },
        "tags": [],
        "id": "4f165487"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 7099708,
          "sourceId": 11563929,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31012,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 6309.002907,
      "end_time": "2025-04-25T17:54:10.897319",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-25T16:09:01.894412",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}